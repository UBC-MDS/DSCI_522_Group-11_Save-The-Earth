{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting CO2 Emission Per Capita for a country using energy consumptions\n",
    "\n",
    "by Tony Shum, Jing Wen, Aishwarya Nadimpally, Weilin Han"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize packages\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer,mean_squared_error,r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the functions from the src folder\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# sys.path.append(os.path.join(os.path.dirname(__file__), '..'))\n",
    "sys.path.append(os.path.join('..'))\n",
    "from src.create_scatter_plot import create_scatter_plot\n",
    "from src.data_preprocessor import data_preprocessor\n",
    "from src.read_melt_merge import read_melt_merge\n",
    "from src.scoring_metrics import scoring_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we attempt to build a prediction model employing the k-nearest neighbours algorithm, designed to leverage energy consumption and energy generation measurements to predict CO2 emissions of a country. Our model's performance on the unseen test dataset is quite commendable, as reflected by an $\\text{R}^2$ of 0.975 and an overall accuracy of 0.976. \n",
    "\n",
    "However, the model's effectiveness lies in its ability to identify instances in the training dataset that closely resemble the data it is trying to predict. This means that when it encounters scenarios not represented in its training data, such as substantial shifts in energy usage or the introduction of new types of clean energy, its predictions may not be as accurate. Consequently, to tackle these potential limitations, it is advisable to continue research efforts to further enhance the model's predictive capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The Intergovernmental Panel on Climate Change (IPCC) identifies CO2 emissions as a primary driver of global warming and climate change {cite}`pachauri2014climate`. Understanding the correlation between consumption of various energy types and CO2 emission is critical for formulating policies aimed at reducing emissions and mitigating climate change impacts {cite}`allen2018special`.\n",
    "\n",
    "Our project aims to estimate a machine learning model that utilizes per capita energy comsumption data to predict per capita CO2 emission for a country. Our model could serve as a potent instrument in raising public awareness about the correlation bewteen energy consumption and CO2 emission, and in the context of international international agreements on emission reductions. We aspire that our research will promote sustainable behavior, such as reducing energy consumption or choosing greener energy alternatives {cite}`energy2018co2`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "The data set that was used in this project is from World Bank via GAPMINDER.ORG, which is an independent Swedish foundation with no political, religious or economic affiliations and the link can be found https://www.gapminder.org/. Each row in the data set represents a comsumption of a certain energy for a certain country at a given year.\n",
    "\n",
    "\n",
    "##### Credential\n",
    "    \n",
    "FREE DATA FROM WORLD BANK VIA GAPMINDER.ORG, CC-BY LICENSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Our data was split into training (80%) and test (20%) set. We opted for the KNeighborsRegressor (KNN) from a pool of prospective models - DummyRegressor, Ridge, SVR - givens its superior predictive accuracy reflected in the highest $\\text{R}^2$ score. The hyperparameter $K$ was tuned using 10-fold cross validation, guided by $R^2$ as the regression metric. Our analytical environment was powered by Python programming language {cite}`Python` along with the several packages: Pandas {cite}`mckinney-proc-scipy-2010`, Altair {cite}`altair`, scikit-learn {cite}`scikit-learn`, Matplotlib {cite}`bisong2019matplotlib`. To perform our analysis and create this report, the code  can be found here: https://github.com/UBC-MDS/DSCI_522_Group-11_Save-The-Earth/tree/main."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results & Discussions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we carried out a cleanup of data types and standardized the units for energy consumption. We then generated histograms for each energy type within the training dataset to gain a comprehensive understanding of our feature distributions and to identify potential outliers. It was observed that the scales for each energy type varied significantly, indicating a need to standardize these scales prior to model construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram by numeric col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To comprehend the variation in energy consumption across different countries, we plotted histograms for each country against the respective years. It was observed that certain countries such as Azerbaijan, Croatia, Estonia, Kazakhstan, Latvia, Lithuania, North Macedonia, Russia, Slovenia, Turkmenistan, Ukraine, and Uzbekistan lacked data prior to 1990. Consequently, we are contemplating the removal of temporal features (year) from our predictors in the model. This is because the scarcity of these features could compromise the accuracy of predictions for the aforementioned countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram by country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Based on the nature of the data and insights from exploratory data analysis (EDA), we're taking several steps in our modeling approach. \n",
    "\n",
    "We're starting with a naive assumption that there's no temporal dependency between observations, essentially treating each year's observations as independent. As a result, we're removing the `year` attribute from our feature set to prevent the model from exploiting this temporal feature for future predictions. However, we may reconsider this approach and explore the use of temporal feature treatment techniques such as time series split and time series cross-validation in later analyses.\n",
    "\n",
    "Next, we're standardizing all numeric features by applying a scaling operation. This process ensures that all features will be on a common scale, which is especially important for algorithms that are sensitive to the scale of the input features.\n",
    "\n",
    "Lastly, we're applying OneHotEncoding to the categorical feature country. This transformation will convert the `country` feature into a more suitable format for our machine learning model, which should help improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used various regression models with $ \\text{R}^ 2 $ as the scoring metrics, and carried out 10-fold cross-validation with each model to find the best performing models.The validation results indicated that the model employing the k-nearest neighbors (k-NN) algorithm had the most commendable performance, with a $ \\text{R}^ 2 $ of 0.949."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter `n_neighbors` and `max_categories` were fine-tuned using 10-fold cross validation with  $ \\text{R}^2 $ as the classification metric to improve the model performance. According to the validation results, this process led to an improved performance of the KNN model, achieving a $ \\text{R}^2 $(`mean_test_r2`) of 0.975."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our predictive model demonstrated a robust performance on the test data, yielding an overall $\\text{R}^2$ of 0.976. This result is encouraging for the task of predicting a country's per capita CO2 emission given the energy generation and consumption data. Moreover, with a Root Mean Square Error (RMSE) of 1.34, our model exhibits a relatively small deviation from residual to the ground truth, meaning that our model is relatively accurate in terms of CO2 emission prediction.\n",
    "\n",
    "To visually evaluate our model's performance, we generated a scatter plot that compared predicted and actual values. This plot demonstrated a strong correlation for lower values, specifically in cases of lower energy consumption, suggesting that our model provides accurate predictions for these scenarios. However, with an increase in values, the model's predictions exhibited greater variability. This heightened discrepancy can potentially be attributed to the scarcity of data points at higher values. Our previous distribution plots revealed a left-skewed data distribution, indicating a lack of sufficient data for higher energy consumption values. Consequently, this limitation could restrict the model's learning capacity, affecting its ability to deliver accurate predictions for higher ranges of energy consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations and Future Direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further improve this model in the future, with hopes of arriving at one that could be used, we suggest several improvements for later revisions. As highlighted during the preprocessing phase, there might be a temporal dependency between observations. Therefore, we could consider incorporating temporal treatments to account for this dependency. \n",
    "\n",
    "We should also consider the collinearity among features. While collinearity might not affect the predictive power of models, it does impact the interpretation of the coefficients in linear models. Collinearity reduction treatments, such as feature removal or dimension reduction techniques, could be considered.\n",
    "\n",
    "Moreover, given the assumption that CO2 emissions may continue to rise in the future, our KNN model might struggle to accurately predict values that lie beyond the range of the training data. In light of this, we could explore other models with similar predictive power that are capable of making accurate predictions for out-of-range input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{bibliography}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q10": {
     "name": "q10",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert area_co2 is not None, 'Your answer does not exist. Have you passed in the correct variable?'\n>>> assert isinstance(area_co2, alt.Chart), 'Your answer is not an altair Chart object. Check to make sure that you have assigned an alt.Chart object.'\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q11": {
     "name": "q11",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert income_hist is not None, 'Your answer does not exist. Have you passed in the correct variable?'\n>>> assert isinstance(income_hist, alt.FacetChart), 'Your answer is not an altair Chart object. Check to make sure that you have assigned an alt.Chart object.'\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q12c": {
     "name": "q12c",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert scatter_lifeexp_familysize_styled is not None, 'Your answer does not exist. Have you passed in the correct variable?'\n>>> assert isinstance(scatter_lifeexp_familysize_styled, alt.Chart), 'Your answer is not an altair Chart object. Check to make sure that you have assigned an alt.Chart object.'\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1w": {
     "name": "q1w",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert scatter is not None\n",
         "failure_message": "Did you assign the plot to the correct variable?",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> assert isinstance(scatter, alt.Chart)\n",
         "failure_message": "Your answer is not an altair Chart object.",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> spec = scatter.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['mark']['type'] == 'point'\n",
         "failure_message": "Make sure you are using the correct mark type.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = scatter.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['x']['field'] == 'Weight_in_lbs'\n",
         "failure_message": "The wrong dataframe column is used for your chart's x channel.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = scatter.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['x']['type'] == 'quantitative'\n",
         "failure_message": "The wrong data type is used for your chart's x channel.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = scatter.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['y']['field'] == 'Horsepower'\n",
         "failure_message": "The wrong dataframe column is used for your chart's y channel.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = scatter.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['y']['type'] == 'quantitative'\n",
         "failure_message": "The wrong data type is used for your chart's y channel.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = scatter.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['color']['field'] == 'Origin'\n",
         "failure_message": "The wrong dataframe column is used for your chart's color channel.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = scatter.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['color']['type'] == 'nominal'\n",
         "failure_message": "The wrong data type is used for your chart's color channel.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2w": {
     "name": "q2w",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert price_lineplot is not None\n",
         "failure_message": "Did you assign the plot to the correct variable?",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> assert isinstance(price_lineplot, alt.Chart)\n",
         "failure_message": "Your answer is not an altair Chart object.",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> spec = price_lineplot.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['mark']['type'] == 'line'\n",
         "failure_message": "Make sure you are using the correct mark type.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = price_lineplot.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['x']['field'] == 'date'\n",
         "failure_message": "The wrong dataframe column is used for your chart's x channel.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = price_lineplot.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['x']['type'] == 'temporal'\n",
         "failure_message": "The wrong data type is used for your chart's x channel.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = price_lineplot.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['y']['field'] == 'price'\n",
         "failure_message": "The wrong dataframe column is used for your chart's y channel.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = price_lineplot.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['y']['type'] == 'quantitative'\n",
         "failure_message": "The wrong data type is used for your chart's y channel.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = price_lineplot.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['color']['field'] == 'symbol'\n",
         "failure_message": "The wrong dataframe column is used for your chart's color channel.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = price_lineplot.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['color']['type'] == 'nominal'\n",
         "failure_message": "The wrong data type is used for your chart's color channel.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert scatter_familysize_lifeexp is not None, 'Your answer does not exist. Have you passed in the correct variable?'\n>>> assert isinstance(scatter_familysize_lifeexp, alt.Chart), 'Your answer is not an altair Chart object. Check to make sure that you have assigned an alt.Chart object.'\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert line_points_education_ratio is not None, 'Your answer does not exist. Have you passed in the correct variable?'\n>>> assert isinstance(line_points_education_ratio, alt.LayerChart), 'Your answer is not a layered altair Chart object. Check to make sure that you have assigned an alt.Chart object.'\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6c": {
     "name": "q6c",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert ci_bands_education_ratio is not None, 'Your answer does not exist. Have you passed in the correct variable?'\n>>> assert isinstance(ci_bands_education_ratio, alt.LayerChart), 'Your answer is not a layered altair Chart object. Check to make sure that you have assigned an alt.Chart object.'\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert scatter_familysize_mortality is not None, 'Your answer does not exist. Have you passed in the correct variable?'\n>>> assert type(scatter_familysize_mortality) == alt.FacetChart, 'Your answer is not an altair Facet Chart object. Check to make sure that you have assigned an alt.Chart object.'\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q9": {
     "name": "q9",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert bars_co2 is not None, 'Your answer does not exist. Have you passed in the correct variable?'\n>>> assert isinstance(bars_co2, alt.Chart), 'Your answer is not an altair Chart object. Check to make sure that you have assigned an alt.Chart object.'\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
