{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting CO2 Emission Per Capita for a country using energy consumptions\n",
    "\n",
    "by Tony Shum, Jing Wen, Aishwarya Nadimpally, Weilin Han"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from myst_nb import glue\n",
    "import pickle\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/plain": "0.99"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "r2_score_train"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/plain": "0.97"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "r2_score_test"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/plain": "0.66"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "rmse_train"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/plain": "1.43"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "rmse_test"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/html": "<style type=\"text/css\">\n</style>\n<table id=\"T_f9c55\">\n  <thead>\n    <tr>\n      <th id=\"T_f9c55_level0_col0\" class=\"col_heading level0 col0\" >r2_score_train</th>\n      <th id=\"T_f9c55_level0_col1\" class=\"col_heading level0 col1\" >r2_score_test</th>\n      <th id=\"T_f9c55_level0_col2\" class=\"col_heading level0 col2\" >rmse_train</th>\n      <th id=\"T_f9c55_level0_col3\" class=\"col_heading level0 col3\" >rmse_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td id=\"T_f9c55_row0_col0\" class=\"data row0 col0\" >0.990000</td>\n      <td id=\"T_f9c55_row0_col1\" class=\"data row0 col1\" >0.970000</td>\n      <td id=\"T_f9c55_row0_col2\" class=\"data row0 col2\" >0.660000</td>\n      <td id=\"T_f9c55_row0_col3\" class=\"data row0 col3\" >1.430000</td>\n    </tr>\n  </tbody>\n</table>\n",
      "application/papermill.record/text/plain": "<pandas.io.formats.style.Styler at 0x2001b7038d0>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "model_scores_df"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_scores_df = pd.read_csv(\"../results/tables/model_scores.csv\").round(2)\n",
    "glue(\"r2_score_train\", model_scores_df['r2_score_train'].values[0], display=False)\n",
    "glue(\"r2_score_test\", model_scores_df['r2_score_test'].values[0], display=False)\n",
    "glue(\"rmse_train\", model_scores_df['rmse_train'].values[0], display=False)\n",
    "glue(\"rmse_test\", model_scores_df['rmse_test'].values[0], display=False)\n",
    "\n",
    "model_scores_df = model_scores_df.style.format().hide()\n",
    "glue(\"model_scores_df\", model_scores_df, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/plain": "'0.953'"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "KNN_reg"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/html": "<style type=\"text/css\">\n</style>\n<table id=\"T_01945\">\n  <thead>\n    <tr>\n      <th id=\"T_01945_level0_col0\" class=\"col_heading level0 col0\" >Unnamed: 0</th>\n      <th id=\"T_01945_level0_col1\" class=\"col_heading level0 col1\" >Baseline</th>\n      <th id=\"T_01945_level0_col2\" class=\"col_heading level0 col2\" >Baseline.1</th>\n      <th id=\"T_01945_level0_col3\" class=\"col_heading level0 col3\" >KNN_reg</th>\n      <th id=\"T_01945_level0_col4\" class=\"col_heading level0 col4\" >KNN_reg.1</th>\n      <th id=\"T_01945_level0_col5\" class=\"col_heading level0 col5\" >Ridge</th>\n      <th id=\"T_01945_level0_col6\" class=\"col_heading level0 col6\" >Ridge.1</th>\n      <th id=\"T_01945_level0_col7\" class=\"col_heading level0 col7\" >SVR</th>\n      <th id=\"T_01945_level0_col8\" class=\"col_heading level0 col8\" >SVR.1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td id=\"T_01945_row0_col0\" class=\"data row0 col0\" >nan</td>\n      <td id=\"T_01945_row0_col1\" class=\"data row0 col1\" >mean</td>\n      <td id=\"T_01945_row0_col2\" class=\"data row0 col2\" >std</td>\n      <td id=\"T_01945_row0_col3\" class=\"data row0 col3\" >mean</td>\n      <td id=\"T_01945_row0_col4\" class=\"data row0 col4\" >std</td>\n      <td id=\"T_01945_row0_col5\" class=\"data row0 col5\" >mean</td>\n      <td id=\"T_01945_row0_col6\" class=\"data row0 col6\" >std</td>\n      <td id=\"T_01945_row0_col7\" class=\"data row0 col7\" >mean</td>\n      <td id=\"T_01945_row0_col8\" class=\"data row0 col8\" >std</td>\n    </tr>\n    <tr>\n      <td id=\"T_01945_row1_col0\" class=\"data row1 col0\" >fit_time</td>\n      <td id=\"T_01945_row1_col1\" class=\"data row1 col1\" >0.006</td>\n      <td id=\"T_01945_row1_col2\" class=\"data row1 col2\" >0.001</td>\n      <td id=\"T_01945_row1_col3\" class=\"data row1 col3\" >0.008</td>\n      <td id=\"T_01945_row1_col4\" class=\"data row1 col4\" >0.002</td>\n      <td id=\"T_01945_row1_col5\" class=\"data row1 col5\" >0.01</td>\n      <td id=\"T_01945_row1_col6\" class=\"data row1 col6\" >0.002</td>\n      <td id=\"T_01945_row1_col7\" class=\"data row1 col7\" >0.285</td>\n      <td id=\"T_01945_row1_col8\" class=\"data row1 col8\" >0.029</td>\n    </tr>\n    <tr>\n      <td id=\"T_01945_row2_col0\" class=\"data row2 col0\" >score_time</td>\n      <td id=\"T_01945_row2_col1\" class=\"data row2 col1\" >0.003</td>\n      <td id=\"T_01945_row2_col2\" class=\"data row2 col2\" >0.001</td>\n      <td id=\"T_01945_row2_col3\" class=\"data row2 col3\" >0.018</td>\n      <td id=\"T_01945_row2_col4\" class=\"data row2 col4\" >0.03</td>\n      <td id=\"T_01945_row2_col5\" class=\"data row2 col5\" >0.003</td>\n      <td id=\"T_01945_row2_col6\" class=\"data row2 col6\" >0.001</td>\n      <td id=\"T_01945_row2_col7\" class=\"data row2 col7\" >0.064</td>\n      <td id=\"T_01945_row2_col8\" class=\"data row2 col8\" >0.012</td>\n    </tr>\n    <tr>\n      <td id=\"T_01945_row3_col0\" class=\"data row3 col0\" >test_r2</td>\n      <td id=\"T_01945_row3_col1\" class=\"data row3 col1\" >-0.003</td>\n      <td id=\"T_01945_row3_col2\" class=\"data row3 col2\" >0.004</td>\n      <td id=\"T_01945_row3_col3\" class=\"data row3 col3\" >0.953</td>\n      <td id=\"T_01945_row3_col4\" class=\"data row3 col4\" >0.022</td>\n      <td id=\"T_01945_row3_col5\" class=\"data row3 col5\" >0.915</td>\n      <td id=\"T_01945_row3_col6\" class=\"data row3 col6\" >0.021</td>\n      <td id=\"T_01945_row3_col7\" class=\"data row3 col7\" >0.714</td>\n      <td id=\"T_01945_row3_col8\" class=\"data row3 col8\" >0.057</td>\n    </tr>\n    <tr>\n      <td id=\"T_01945_row4_col0\" class=\"data row4 col0\" >train_r2</td>\n      <td id=\"T_01945_row4_col1\" class=\"data row4 col1\" >0.0</td>\n      <td id=\"T_01945_row4_col2\" class=\"data row4 col2\" >0.0</td>\n      <td id=\"T_01945_row4_col3\" class=\"data row4 col3\" >0.975</td>\n      <td id=\"T_01945_row4_col4\" class=\"data row4 col4\" >0.003</td>\n      <td id=\"T_01945_row4_col5\" class=\"data row4 col5\" >0.926</td>\n      <td id=\"T_01945_row4_col6\" class=\"data row4 col6\" >0.002</td>\n      <td id=\"T_01945_row4_col7\" class=\"data row4 col7\" >0.726</td>\n      <td id=\"T_01945_row4_col8\" class=\"data row4 col8\" >0.006</td>\n    </tr>\n  </tbody>\n</table>\n",
      "application/papermill.record/text/plain": "<pandas.io.formats.style.Styler at 0x2001d830210>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "model_selection_scores_df"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_selection_scores_df = pd.read_csv(\"../results/tables/model_selection_scores.csv\")\n",
    "glue(\"KNN_reg\", model_selection_scores_df['KNN_reg'].values[3], display=False)\n",
    "\n",
    "model_selection_scores_df = model_selection_scores_df.style.format().hide()\n",
    "glue(\"model_selection_scores_df\", model_selection_scores_df, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/plain": "0.973"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "mean_test_r2"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/html": "<style type=\"text/css\">\n</style>\n<table id=\"T_f2396\">\n  <thead>\n    <tr>\n      <th id=\"T_f2396_level0_col0\" class=\"col_heading level0 col0\" >param_columntransformer__onehotencoder__max_categories</th>\n      <th id=\"T_f2396_level0_col1\" class=\"col_heading level0 col1\" >param_kneighborsregressor__n_neighbors</th>\n      <th id=\"T_f2396_level0_col2\" class=\"col_heading level0 col2\" >mean_test_r2</th>\n      <th id=\"T_f2396_level0_col3\" class=\"col_heading level0 col3\" >std_test_r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td id=\"T_f2396_row0_col0\" class=\"data row0 col0\" >47</td>\n      <td id=\"T_f2396_row0_col1\" class=\"data row0 col1\" >2</td>\n      <td id=\"T_f2396_row0_col2\" class=\"data row0 col2\" >0.973000</td>\n      <td id=\"T_f2396_row0_col3\" class=\"data row0 col3\" >0.015000</td>\n    </tr>\n    <tr>\n      <td id=\"T_f2396_row1_col0\" class=\"data row1 col0\" >49</td>\n      <td id=\"T_f2396_row1_col1\" class=\"data row1 col1\" >19</td>\n      <td id=\"T_f2396_row1_col2\" class=\"data row1 col2\" >0.894000</td>\n      <td id=\"T_f2396_row1_col3\" class=\"data row1 col3\" >0.022000</td>\n    </tr>\n    <tr>\n      <td id=\"T_f2396_row2_col0\" class=\"data row2 col0\" >9</td>\n      <td id=\"T_f2396_row2_col1\" class=\"data row2 col1\" >9</td>\n      <td id=\"T_f2396_row2_col2\" class=\"data row2 col2\" >0.913000</td>\n      <td id=\"T_f2396_row2_col3\" class=\"data row2 col3\" >0.026000</td>\n    </tr>\n    <tr>\n      <td id=\"T_f2396_row3_col0\" class=\"data row3 col0\" >62</td>\n      <td id=\"T_f2396_row3_col1\" class=\"data row3 col1\" >7</td>\n      <td id=\"T_f2396_row3_col2\" class=\"data row3 col2\" >0.937000</td>\n      <td id=\"T_f2396_row3_col3\" class=\"data row3 col3\" >0.024000</td>\n    </tr>\n    <tr>\n      <td id=\"T_f2396_row4_col0\" class=\"data row4 col0\" >49</td>\n      <td id=\"T_f2396_row4_col1\" class=\"data row4 col1\" >13</td>\n      <td id=\"T_f2396_row4_col2\" class=\"data row4 col2\" >0.911000</td>\n      <td id=\"T_f2396_row4_col3\" class=\"data row4 col3\" >0.023000</td>\n    </tr>\n    <tr>\n      <td id=\"T_f2396_row5_col0\" class=\"data row5 col0\" >76</td>\n      <td id=\"T_f2396_row5_col1\" class=\"data row5 col1\" >9</td>\n      <td id=\"T_f2396_row5_col2\" class=\"data row5 col2\" >0.922000</td>\n      <td id=\"T_f2396_row5_col3\" class=\"data row5 col3\" >0.024000</td>\n    </tr>\n    <tr>\n      <td id=\"T_f2396_row6_col0\" class=\"data row6 col0\" >70</td>\n      <td id=\"T_f2396_row6_col1\" class=\"data row6 col1\" >4</td>\n      <td id=\"T_f2396_row6_col2\" class=\"data row6 col2\" >0.963000</td>\n      <td id=\"T_f2396_row6_col3\" class=\"data row6 col3\" >0.019000</td>\n    </tr>\n    <tr>\n      <td id=\"T_f2396_row7_col0\" class=\"data row7 col0\" >36</td>\n      <td id=\"T_f2396_row7_col1\" class=\"data row7 col1\" >15</td>\n      <td id=\"T_f2396_row7_col2\" class=\"data row7 col2\" >0.903000</td>\n      <td id=\"T_f2396_row7_col3\" class=\"data row7 col3\" >0.023000</td>\n    </tr>\n    <tr>\n      <td id=\"T_f2396_row8_col0\" class=\"data row8 col0\" >12</td>\n      <td id=\"T_f2396_row8_col1\" class=\"data row8 col1\" >5</td>\n      <td id=\"T_f2396_row8_col2\" class=\"data row8 col2\" >0.948000</td>\n      <td id=\"T_f2396_row8_col3\" class=\"data row8 col3\" >0.020000</td>\n    </tr>\n    <tr>\n      <td id=\"T_f2396_row9_col0\" class=\"data row9 col0\" >34</td>\n      <td id=\"T_f2396_row9_col1\" class=\"data row9 col1\" >12</td>\n      <td id=\"T_f2396_row9_col2\" class=\"data row9 col2\" >0.912000</td>\n      <td id=\"T_f2396_row9_col3\" class=\"data row9 col3\" >0.024000</td>\n    </tr>\n    <tr>\n      <td id=\"T_f2396_row10_col0\" class=\"data row10 col0\" >3</td>\n      <td id=\"T_f2396_row10_col1\" class=\"data row10 col1\" >17</td>\n      <td id=\"T_f2396_row10_col2\" class=\"data row10 col2\" >0.896000</td>\n      <td id=\"T_f2396_row10_col3\" class=\"data row10 col3\" >0.024000</td>\n    </tr>\n    <tr>\n      <td id=\"T_f2396_row11_col0\" class=\"data row11 col0\" >2</td>\n      <td id=\"T_f2396_row11_col1\" class=\"data row11 col1\" >14</td>\n      <td id=\"T_f2396_row11_col2\" class=\"data row11 col2\" >0.902000</td>\n      <td id=\"T_f2396_row11_col3\" class=\"data row11 col3\" >0.022000</td>\n    </tr>\n    <tr>\n      <td id=\"T_f2396_row12_col0\" class=\"data row12 col0\" >69</td>\n      <td id=\"T_f2396_row12_col1\" class=\"data row12 col1\" >7</td>\n      <td id=\"T_f2396_row12_col2\" class=\"data row12 col2\" >0.937000</td>\n      <td id=\"T_f2396_row12_col3\" class=\"data row12 col3\" >0.024000</td>\n    </tr>\n    <tr>\n      <td id=\"T_f2396_row13_col0\" class=\"data row13 col0\" >53</td>\n      <td id=\"T_f2396_row13_col1\" class=\"data row13 col1\" >3</td>\n      <td id=\"T_f2396_row13_col2\" class=\"data row13 col2\" >0.967000</td>\n      <td id=\"T_f2396_row13_col3\" class=\"data row13 col3\" >0.021000</td>\n    </tr>\n    <tr>\n      <td id=\"T_f2396_row14_col0\" class=\"data row14 col0\" >22</td>\n      <td id=\"T_f2396_row14_col1\" class=\"data row14 col1\" >7</td>\n      <td id=\"T_f2396_row14_col2\" class=\"data row14 col2\" >0.928000</td>\n      <td id=\"T_f2396_row14_col3\" class=\"data row14 col3\" >0.024000</td>\n    </tr>\n    <tr>\n      <td id=\"T_f2396_row15_col0\" class=\"data row15 col0\" >38</td>\n      <td id=\"T_f2396_row15_col1\" class=\"data row15 col1\" >9</td>\n      <td id=\"T_f2396_row15_col2\" class=\"data row15 col2\" >0.920000</td>\n      <td id=\"T_f2396_row15_col3\" class=\"data row15 col3\" >0.025000</td>\n    </tr>\n    <tr>\n      <td id=\"T_f2396_row16_col0\" class=\"data row16 col0\" >68</td>\n      <td id=\"T_f2396_row16_col1\" class=\"data row16 col1\" >4</td>\n      <td id=\"T_f2396_row16_col2\" class=\"data row16 col2\" >0.963000</td>\n      <td id=\"T_f2396_row16_col3\" class=\"data row16 col3\" >0.019000</td>\n    </tr>\n    <tr>\n      <td id=\"T_f2396_row17_col0\" class=\"data row17 col0\" >67</td>\n      <td id=\"T_f2396_row17_col1\" class=\"data row17 col1\" >12</td>\n      <td id=\"T_f2396_row17_col2\" class=\"data row17 col2\" >0.914000</td>\n      <td id=\"T_f2396_row17_col3\" class=\"data row17 col3\" >0.022000</td>\n    </tr>\n    <tr>\n      <td id=\"T_f2396_row18_col0\" class=\"data row18 col0\" >66</td>\n      <td id=\"T_f2396_row18_col1\" class=\"data row18 col1\" >6</td>\n      <td id=\"T_f2396_row18_col2\" class=\"data row18 col2\" >0.947000</td>\n      <td id=\"T_f2396_row18_col3\" class=\"data row18 col3\" >0.024000</td>\n    </tr>\n    <tr>\n      <td id=\"T_f2396_row19_col0\" class=\"data row19 col0\" >69</td>\n      <td id=\"T_f2396_row19_col1\" class=\"data row19 col1\" >17</td>\n      <td id=\"T_f2396_row19_col2\" class=\"data row19 col2\" >0.902000</td>\n      <td id=\"T_f2396_row19_col3\" class=\"data row19 col3\" >0.022000</td>\n    </tr>\n  </tbody>\n</table>\n",
      "application/papermill.record/text/plain": "<pandas.io.formats.style.Styler at 0x2001b6e24d0>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "hyperparameter_tuning_scores_df"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyperparameter_tuning_scores_df = pd.read_csv(\"../results/tables/hyperparameter_tuning_scores.csv\").round(3)\n",
    "\n",
    "glue(\"mean_test_r2\", hyperparameter_tuning_scores_df['mean_test_r2'].values[0], display=False)\n",
    "\n",
    "hyperparameter_tuning_scores_df = hyperparameter_tuning_scores_df.style.format().hide()\n",
    "glue(\"hyperparameter_tuning_scores_df\", hyperparameter_tuning_scores_df, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we attempt to build a prediction model employing the k-nearest neighbours algorithm, designed to leverage energy consumption and energy generation measurements to predict CO2 emissions of a country. Our model's performance on the unseen test dataset is quite commendable, as reflected by an $\\text{R}^2$ of {glue:text}`r2_score_test`.\n",
    "\n",
    "However, the model's effectiveness lies in its ability to identify instances in the training dataset that closely resemble the data it is trying to predict. This means that when it encounters scenarios not represented in its training data, such as substantial shifts in energy usage or the introduction of new types of clean energy, its predictions may not be as accurate. Consequently, to tackle these potential limitations, it is advisable to continue research efforts to further enhance the model's predictive capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The Intergovernmental Panel on Climate Change (IPCC) identifies CO2 emissions as a primary driver of global warming and climate change {cite}`pachauri2014climate`. Understanding the correlation between consumption of various energy types and CO2 emission is critical for formulating policies aimed at reducing emissions and mitigating climate change impacts {cite}`allen2018special`.\n",
    "\n",
    "Our project aims to estimate a machine learning model that utilizes per capita energy consumption data to predict per capita CO2 emission for a country. Our model could serve as a potent instrument in raising public awareness about the correlation between energy consumption and CO2 emission, and in the context of international international agreements on emission reductions. We aspire that our research will promote sustainable behavior, such as reducing energy consumption or choosing greener energy alternatives {cite}`energy2018co2`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "The data set that was used in this project is from World Bank via GAPMINDER.ORG, which is an independent Swedish foundation with no political, religious or economic affiliations and the link can be found https://www.gapminder.org/. Each row in the data set represents a consumption of a certain energy for a certain country at a given year.\n",
    "\n",
    "\n",
    "##### Credential\n",
    "    \n",
    "FREE DATA FROM WORLD BANK VIA GAPMINDER.ORG, CC-BY LICENSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Our data was split into training (80%) and test (20%) set. We opted for the KNeighborsRegressor (KNN) from a pool of prospective models - DummyRegressor, Ridge, SVR - givens its superior predictive accuracy reflected in the highest $\\text{R}^2$ score. The hyperparameter $K$ was tuned using 10-fold cross validation, guided by $R^2$ as the regression metric. Our analytical environment was powered by Python programming language {cite}`Python` along with the several packages: Pandas {cite}`mckinney-proc-scipy-2010`, Altair {cite}`altair`, scikit-learn {cite}`scikit-learn`, Matplotlib {cite}`bisong2019matplotlib`. To perform our analysis and create this report, the code  can be found here: https://github.com/UBC-MDS/DSCI_522_Group-11_Save-The-Earth/tree/main."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results & Discussions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we carried out a cleanup of data types and standardized the units for energy consumption. We then generated histograms ({numref}Figure {number} <histogram_by_numeric_cols>)for each energy type within the training dataset to gain a comprehensive understanding of our feature distributions and to identify potential outliers. It was observed that the scales for each energy type varied significantly, indicating a need to standardize these scales prior to model construction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../results/figures/histogram_by_numeric_cols.png\n",
    "---\n",
    "width: 600px\n",
    "name: histogram_by_numeric_cols\n",
    "---\n",
    "Number of records of all numeric features.\n",
    "\n",
    "From left to right: number of records of each year, CO2 Emmision, Coal Consumption, Electricity Generation, Electricity Consumption, Hydro Energy Generation, Nuclear Energy Generation, Gas Generation, Oil Consumption, Oil Generation.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To comprehend the variation in energy consumption across different countries, we plotted histograms for each country against the respective years({numref}Figure {number} <histogram_by_country>). It was observed that certain countries such as Azerbaijan, Croatia, Estonia, Kazakhstan, Latvia, Lithuania, North Macedonia, Russia, Slovenia, Turkmenistan, Ukraine, and Uzbekistan lacked data prior to 1990. Consequently, we are contemplating the removal of temporal features (year) from our predictors in the model. This is because the scarcity of these features could compromise the accuracy of predictions for the aforementioned countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../results/figures/histogram_by_country.png\n",
    "---\n",
    "width: 600px\n",
    "name: histogram_by_country\n",
    "---\n",
    "Number of records of all countries.\n",
    "\n",
    "From left to right: All the countries with records of CO2 Emmision, Coal Consumption, Oil Consumption and Electricity Consumption, in alphabetic order .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Based on the nature of the data and insights from exploratory data analysis (EDA), we're taking several steps in our modeling approach. \n",
    "\n",
    "We're starting with a naive assumption that there's no temporal dependency between observations, essentially treating each year's observations as independent. As a result, we're removing the `year` attribute from our feature set to prevent the model from exploiting this temporal feature for future predictions. However, we may reconsider this approach and explore the use of temporal feature treatment techniques such as time series split and time series cross-validation in later analyses.\n",
    "\n",
    "Next, we're standardizing all numeric features by applying a scaling operation. This process ensures that all features will be on a common scale, which is especially important for algorithms that are sensitive to the scale of the input features.\n",
    "\n",
    "Lastly, we're applying OneHotEncoding to the categorical feature country. This transformation will convert the `country` feature into a more suitable format for our machine learning model, which should help improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used various regression models with $ \\text{R}^ 2 $ as the scoring metrics, and carried out 10-fold cross-validation with each model to find the best performing models.The validation results indicated that the model employing the k-nearest neighbors (k-NN) algorithm had the most commendable performance, with a $ \\text{R}^ 2 $ of {glue:text}`KNN_reg`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter `n_neighbors` and `max_categories` were fine-tuned using 10-fold cross validation with  $ \\text{R}^2 $ as the classification metric to improve the model performance. According to the validation results, this process led to an improved performance of the KNN model, achieving a $ \\text{R}^2 $(`mean_test_r2`) of {glue:text}`mean_test_r2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our predictive model demonstrated a robust performance on the test data, yielding an overall $\\text{R}^2$ of {glue:text}`r2_score_test`. This result is encouraging for the task of predicting a country's per capita CO2 emission given the energy generation and consumption data. Moreover, with a Root Mean Square Error (RMSE) of {glue:text}`rmse_test`, our model exhibits a relatively small deviation from residual to the ground truth, meaning that our model is relatively accurate in terms of CO2 emission prediction.\n",
    "\n",
    "To visually evaluate our model's performance, we generated a scatter plot that compared predicted and actual values ({numref}Figure {number} <scatter_plot>). This plot demonstrated a strong correlation for lower values, specifically in cases of lower energy consumption, suggesting that our model provides accurate predictions for these scenarios. However, with an increase in values, the model's predictions exhibited greater variability. This heightened discrepancy can potentially be attributed to the scarcity of data points at higher values. Our previous distribution plots revealed a left-skewed data distribution, indicating a lack of sufficient data for higher energy consumption values. Consequently, this limitation could restrict the model's learning capacity, affecting its ability to deliver accurate predictions for higher ranges of energy consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../results/figures/scatter_plot.png\n",
    "---\n",
    "width: 600px\n",
    "name: scatter_plot\n",
    "---\n",
    "Comparison between predicted value and actual value.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations and Future Direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further improve this model in the future, with hopes of arriving at one that could be used, we suggest several improvements for later revisions. As highlighted during the preprocessing phase, there might be a temporal dependency between observations. Therefore, we could consider incorporating temporal treatments to account for this dependency. \n",
    "\n",
    "We should also consider the collinearity among features. While collinearity might not affect the predictive power of models, it does impact the interpretation of the coefficients in linear models. Collinearity reduction treatments, such as feature removal or dimension reduction techniques, could be considered.\n",
    "\n",
    "Moreover, given the assumption that CO2 emissions may continue to rise in the future, our KNN model might struggle to accurately predict values that lie beyond the range of the training data. In light of this, we could explore other models with similar predictive power that are capable of making accurate predictions for out-of-range input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{bibliography}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "522project",
   "language": "python",
   "name": "522project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q10": {
     "name": "q10",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert area_co2 is not None, 'Your answer does not exist. Have you passed in the correct variable?'\n>>> assert isinstance(area_co2, alt.Chart), 'Your answer is not an altair Chart object. Check to make sure that you have assigned an alt.Chart object.'\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q11": {
     "name": "q11",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert income_hist is not None, 'Your answer does not exist. Have you passed in the correct variable?'\n>>> assert isinstance(income_hist, alt.FacetChart), 'Your answer is not an altair Chart object. Check to make sure that you have assigned an alt.Chart object.'\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q12c": {
     "name": "q12c",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert scatter_lifeexp_familysize_styled is not None, 'Your answer does not exist. Have you passed in the correct variable?'\n>>> assert isinstance(scatter_lifeexp_familysize_styled, alt.Chart), 'Your answer is not an altair Chart object. Check to make sure that you have assigned an alt.Chart object.'\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1w": {
     "name": "q1w",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert scatter is not None\n",
         "failure_message": "Did you assign the plot to the correct variable?",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> assert isinstance(scatter, alt.Chart)\n",
         "failure_message": "Your answer is not an altair Chart object.",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> spec = scatter.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['mark']['type'] == 'point'\n",
         "failure_message": "Make sure you are using the correct mark type.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = scatter.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['x']['field'] == 'Weight_in_lbs'\n",
         "failure_message": "The wrong dataframe column is used for your chart's x channel.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = scatter.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['x']['type'] == 'quantitative'\n",
         "failure_message": "The wrong data type is used for your chart's x channel.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = scatter.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['y']['field'] == 'Horsepower'\n",
         "failure_message": "The wrong dataframe column is used for your chart's y channel.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = scatter.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['y']['type'] == 'quantitative'\n",
         "failure_message": "The wrong data type is used for your chart's y channel.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = scatter.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['color']['field'] == 'Origin'\n",
         "failure_message": "The wrong dataframe column is used for your chart's color channel.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = scatter.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['color']['type'] == 'nominal'\n",
         "failure_message": "The wrong data type is used for your chart's color channel.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2w": {
     "name": "q2w",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert price_lineplot is not None\n",
         "failure_message": "Did you assign the plot to the correct variable?",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> assert isinstance(price_lineplot, alt.Chart)\n",
         "failure_message": "Your answer is not an altair Chart object.",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> spec = price_lineplot.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['mark']['type'] == 'line'\n",
         "failure_message": "Make sure you are using the correct mark type.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = price_lineplot.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['x']['field'] == 'date'\n",
         "failure_message": "The wrong dataframe column is used for your chart's x channel.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = price_lineplot.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['x']['type'] == 'temporal'\n",
         "failure_message": "The wrong data type is used for your chart's x channel.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = price_lineplot.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['y']['field'] == 'price'\n",
         "failure_message": "The wrong dataframe column is used for your chart's y channel.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = price_lineplot.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['y']['type'] == 'quantitative'\n",
         "failure_message": "The wrong data type is used for your chart's y channel.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = price_lineplot.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['color']['field'] == 'symbol'\n",
         "failure_message": "The wrong dataframe column is used for your chart's color channel.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> spec = price_lineplot.copy()\n>>> with alt.data_transformers.enable('default'):\n...     spec['data'] = spec['data'][:1]\n...     spec = spec.to_dict()\n>>> assert spec['encoding']['color']['type'] == 'nominal'\n",
         "failure_message": "The wrong data type is used for your chart's color channel.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert scatter_familysize_lifeexp is not None, 'Your answer does not exist. Have you passed in the correct variable?'\n>>> assert isinstance(scatter_familysize_lifeexp, alt.Chart), 'Your answer is not an altair Chart object. Check to make sure that you have assigned an alt.Chart object.'\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert line_points_education_ratio is not None, 'Your answer does not exist. Have you passed in the correct variable?'\n>>> assert isinstance(line_points_education_ratio, alt.LayerChart), 'Your answer is not a layered altair Chart object. Check to make sure that you have assigned an alt.Chart object.'\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6c": {
     "name": "q6c",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert ci_bands_education_ratio is not None, 'Your answer does not exist. Have you passed in the correct variable?'\n>>> assert isinstance(ci_bands_education_ratio, alt.LayerChart), 'Your answer is not a layered altair Chart object. Check to make sure that you have assigned an alt.Chart object.'\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert scatter_familysize_mortality is not None, 'Your answer does not exist. Have you passed in the correct variable?'\n>>> assert type(scatter_familysize_mortality) == alt.FacetChart, 'Your answer is not an altair Facet Chart object. Check to make sure that you have assigned an alt.Chart object.'\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q9": {
     "name": "q9",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert bars_co2 is not None, 'Your answer does not exist. Have you passed in the correct variable?'\n>>> assert isinstance(bars_co2, alt.Chart), 'Your answer is not an altair Chart object. Check to make sure that you have assigned an alt.Chart object.'\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
